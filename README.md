## <a name="contents"></a>Архитектура высоконагруженных систем
1. [Метрики качества](#metrics)
2. [Проблемы нагрузок](#problems)
3. [Тестирование производительности](#testing)

### <a name="metrics"></a> Метрики качества
#### Что мерять
- `rps`, `rpm` - количество запросов в единицу времени
- `pps` (packets per second), `mps` (megabytes ...) - количество данных в единицу времени
- `simultaneous connections`, `concurrency` - количество одновременных соединений
- `latency` - задержка ответа
- `throughput` - пропускная способность системы (в хайлоад жертвуют latency ради этого)

#### Как мерять
Статистические величины (95, 99) - перцентили

#### Виды масштабирования
- Вертикальное - увеличение мощности сервера
- Горизонтальное - использование большего количества серверов

 [ к оглавлению >>](#contents)
 
 ### <a name="problems"></a> Проблемы нагрузок
 #### Переключение контекста
 В операционных системах с планировщиком задач существует проблема переключения контекста
 между задачами и потоками, так как необходимо пройти несколько этапов
 - Сохранение регистров процессора
 - Сохранение общей информации pid, tid, uid, gid, euid, egid и т. д.
 - Сохранение состояния процесса/потока
 - Сохранение прав доступа
 - Сохранение используемых потоком ресурсов и блокировок
 - Сохранение счетчики использования ресурсов (например, таймеры использованного процессорного времени)
 - Сохранение регионов памяти, выделенных процессу
 - Очистка конвейера команд и данных процессора
 - Очистка TLB, отвечающий за страничное отображение линейных адресов на физические
 #### Процессы и потоки
 В системе linux процессы и потоки отличаются доступом к памяти. У потоков она общая
 - создание процесса
 ```shell script
      clone(
          child_stack=0, 
          ags=CLONE_CHILD_CLEARTID |
              CLONE_CHILD_SETTID |
              SIGCHLD, 
          child_tidptr=0x7fa001a93a10) = 6916
```
- создание потока
```shell script
    clone(
      child_stack=0,
      ags=CLONE_VM|
          CLONE_FS|
          CLONE_FILES|
          CLONE_SYSVSEM|
          CLONE_SIGHAND|
          CLONE_THREAD|
          CLONE_SETTLS|
          CLONE_PARENT_S
      child_tidptr=0x7fa001a93a10) = 6916
```
#### Модели Веб серверов
- worker (многопоточный)
- prefork (многопроцессный)
- синхронный (select)
- async (асинхронный epol)
- Комбинированные варианты

#### worker vs prefork
- переключение контекста между потоками менее затратное
- меньше потребление памяти
- потоки сложнее синхронизировать

####  Блокирующие и неблокирующие системные вызовы
Блокирующие системные вызовы блокируют процесс (или поток) до того, как будут получены данные (часть данных).
Во время блокировки процесс не потребляет процессорное время, но потребляет память.
Чтение из сети может быть неблокирующим. В неблокирующем режиме чтение из сокета возвращает или ответ (хотя
бы его часть), или сообщение, что данные еще не готовы.
Чтение с диска может быть только блокирующим(*)

- Apache - синхронный многопроцессный
- Nginx - асинхронный многопоточный

#### Концепция Fiber
- Асинхронный код - быстрый, потребляет мало памяти.
- Асинхронный код - сложно писать.
- Синхронный код - медленее, потребляет больше памяти.
- Синхронный код - просто писать.

#### Обзор языков программирования
- Perl
    - Обычно работает внутри apache.
    - Синхнронный язык с поддержкой тредов (редко).
    - Есть библиотека AnyEvent (еще реже тредов)
    - Есть библиотека для fiber
- Php
    - CLI SAPI - в качестве консольной команды php для запуска наших кронов и других cli-программ
(Command Line Interface)
    - apxs2 SAPI - в качестве модуля к apache2
    - CGI SAPI - в качестве запускаемого на каждом запросе CGI (сейчас так почти никто не делает)
    - FPM SAPI - Fast Process Manager, написанный для PHP разработчиками из комании Badoo и
теперь поддерживаемый сообществом
    - Можно делать потоки, но редко используется.

- Python
    - Есть потоки.
    - Есть fiber.
    - Процесс с потоками в Python может утилизировать только одно ядро процессора

 - Node.js
    - Асинхронный код.
    - Строго однопоточный.
    
- Go
    - Концепция зеленых тредов.
    - Умеет использовать столько ядер ЦПУ, сколько нужно.
    - Ориентирован на микросервисы.
    - Быстрый.
    
#### Трехзвенная архитектура
Frontend, Backend, Storage
- Задачи frontend (reverse proxy)
    - Терминировать ssl-соединения.
    - Обработка медленных клиентов.
    - Отдача статики.
    - Keep-Alive.
    - Кэширование.
    - Балансировка.
    - Роутинг по бэкендам
- Задачи backend
    - Бизнес-логика
    - Ожидание ответов от хранилищ
- Задачи хранилищ
- Хранение информации
- Быстрый поиск (индексы)
- Обеспечение транзакционности (ACID)

#### Библиография
- Node.js multithreading: What are Worker Threads and why do they matter? - LogRocket Blog
https://blog.logrocket.com/node-js-multithreading-what-are-worker-threads-and-why-do-they-matter-48ab102f8b10/

- Влияние Transparent Huge Pages на производительность системы
https://habr.com/ru/company/tinkoff/blog/446342/

- Is this explanation about VSS/RSS/PSS/USS accurate?
https://stackoverflow.com/questions/22372960/is-this-explanation-about-vss-rss-pss-uss-accurate

 [ к оглавлению >>](#contents)
 
### <a name="testing"></a> Тестирование производительности
#### Области 
- Администраторы, backend
    - Быстрые ответы сервера
    - Эффективное использование оборудования
- Проектировщики интерфейсов, Frontend, Android, iOs
    - Клиентская оптимизация, быстрая отрисовка
    - Энергоэффективность
- Аналитики
    - Удобство использования
    - Понятность бизнес-процесса, запоминаемость
#### Тестирование производительности
##### Подсисием серверов
- нагрузка на диск
    - fio - flexible i/o tester [https://github.com/axboe/fio](https://github.com/axboe/fio)
        - The following example benchmarks maximum write throughput:
        ```shell script
             fio --ioengine=sync --direct=0 \
             --fsync_on_close=1 --randrepeat=0 --nrfiles=1  --name=seqwrite --rw=write \
             --bs=1m --size=20G --end_fsync=1 --fallocate=none  --overwrite=0 --numjobs=1 \
             --directory=/mnt/gcfs --loops=10
        ```
        - The following example benchmarks maximum write IOPS:
        ```shell script
            fio --ioengine=sync --direct=0 \
            --fsync_on_close=1 --randrepeat=0 --nrfiles=1  --name=randwrite --rw=randwrite \
            --bs=4K --size=1G --end_fsync=1 --fallocate=none  --overwrite=0 --numjobs=80 \
            --sync=1 --directory=/mnt/standard --loops=10
        ```
- нагрузка на процессор
    - Phoronix [https://phoronix-test-suite.com/](https://phoronix-test-suite.com/)
        ```shell script
         phoronix-test-suite benchmark smallpt
             Test Results:
                 57.683207988739
                 57.237819910049
                 57.684161901474
             Average: 57.54 Seconds
       ```
- нагрузка на сеть
    - iperf3 [https://software.es.net/iperf/](https://software.es.net/iperf/)
        ```shell script
            iperf3 -s
            iperf3 -c 192.168.1.66
            [ ID] Interval           Transfer     Bandwidth       Retr
            [  4]   0.00-10.00  sec  42.9 GBytes  36.8 Gbits/sec    0             sender
            [  4]   0.00-10.00  sec  42.9 GBytes  36.8 Gbits/sec  
        ```
##### Cерверов приложений на простых запросах
- Подать нагрузку на балансировщик
    - `httpperf`, `ab`
- Подать нагрузку на сервер баз данных
    - `sysbench` (MySQL), `pgbench` (PostgreeSQL) 
- Подать нагрузку на сервер приложений
    - `curl`, `wget`, `ab`
    - на уровне TCP - `tcpreplay`
##### Приложений при выполнении сценариев
Производятся динамически связанные запросы к системе, связанные со сценариями пользовательской активности, с высокой интенсивностью
- Самописные утилиты "Бешенный пользователь"
- Функциональный тест без пауз в несколько потоков

##### В соответствии с требованиями
Производится точная нагрузка, в подходящее время, в нужном месте, с нужной силой, с анализом происходящего
- Appache.JMeter - простые сценарии (Groovy, Java, JavaScript)
- Gatling - сложные сценарии с десятками зпросов (Scala)
- wrk - автоматизация на Lua
- Yandex.Tank - единый отчет, масштабирование (Go, Pyhon)


#### Валидация результатов
- Смоделировать нагрузку
- Отладить мониторинг (для сравнения результатов теста с показателями мониторинга систем)
  - `TIG` - Telegraph, InfluxDB, Grafana
  - `Prometheus` - Telegraf, Prometheus, Grafana
  - `Zabbix` - Zabbix, Grafana. 
- Сравнить со стандартами для оборудования
#### Виды тестиования производительности

![](img/30.png)

- Нагрузочное (load testing) - выполнение программы с повышением нагрузки от среднего профиля до максимального и выше
    - подаем нагрузку ступенями, наращиваем количество операций в единицу времени ( выдержит ли система нагрузку, есть ли узкие места)
    ![](img/01.png)
    - выше максимума, чтобы знать есть ли запас
    ![](img/02.png)
    - ищем точку деградации и доступности (timeout, 504)
    ![](img/03.png)
    - сравниваем с профилем нагрузки (min, med, max)
    ![](img/04.png)
    - ищем узкое место, лимиты, в.т.ч конфигурационные
    ![](img/05.png)
    - необходимо понимание работы системы
    ![](img/06.png)
    - ищем точку появления ошибок под нагрузкой
    ![](img/07.png)
    - стараемся избавиться от ошибок и предупреждений
    ![](img/08.png)
    - их их отношения к профилю нагрузки (med, max)
    ![](img/09.png)
    - выбираем профиль для теста стабильности (80% от точки деградации)
    ![](img/10.png)
    
- Стабильности (stability testing) - длительное тестирование со средней нагрузкой, поиском отклонений и проверками корректности работы 
(что будет при эксплуатации 24/7, стабильна ли система под нагрузкой, как быстро растет размер базы данных, есть ли утечка соединений,
нет ли потерь данных)
    - не выше предельной, чтобы не было ошибок
    ![](img/11.png)
    -  всю ночь или все выходные
    ![](img/12.png)
    - выполняются во время или между интерациями
    ![](img/13.png)
    - попадут в отчет по тестированию стабильности
    ![](img/14.png)
    
   
- Стрессовое (stress testing) - тестирование за пределами рабочих нагрузок в ограниченных ресурсах (если нагрузка ненадолго превысит максимум,
освобождаются ли неиспользуемые ресурсы, восстановится ли система после ошибок, какие ошибки проявляются под нагрузкой)
    - быстро и ненадолго повысим нагрузку и повторим такой процесс несколько раз
    ![](img/15.png)
    - Выявим утечку ресурсов, проверим корректность обработки исключений
    ![](img/16.png)
    - выявим утечку ресурсов, возможно, что ресурсы не освобождаются полностью
    ![](img/17.png)
    - возможно, что ресурсы не освобождаются частично
    ![](img/18.png)
    - быстро ли разбираются внутренние очереди системы
    ![](img/19.png)
    
- Обьемное (volume testing) - тестирование при увеличении обьемов данных (что будет через 5 лет работы, а если увеличить размер документов)
    - сценарий через 1 год работы
    ![](img/20.png)
    - сценнарий через 5 лет работы
    ![](img/21.png)
    - сценарий через 10 лет работы
    ![](img/22.png)
    > - нужен генератор баз данных и лучше его писать на SQL
    - профиль нагрузки - размер пакета данных
     ![](img/23.png)                                                                                                                                                                                                                                                                                                      >

- Масштабируемости (scalability testing) - серия нагрузочных тестов для разных профилей оборудования, количества серверов или узлов системы,
настроек - размеров очередей, лимитов (поможет ли увеличение памяти в 2 раза, какой предел на другом железе, какая производительность
на двух серверах)
    - Наращивание мощьности оборудования вертикальное масштабирование
    ![](img/24.png)
    - Тестирование на разных конфигурациях для прогноза затрат
    ![](img/25.png)
    - Наращивание мощьности оборудования имеет технический предел
    ![](img/26.png)
    - Наращивание количества узлов горизонтальное масштабирование
    ![](img/27.png)
    - Наращивание количества узлов закладывается в архитектуру
    ![](img/28.png)
    - Наращивание количества узлов - дает гибкость
    ![](img/29.png)

#### Генерация данных
- Лучше всего использовать SQL для генерации данных
    - высокая скорость генерации
    - можно сгенерировать 100Гбайт
    - не нужны интеграции
    - SQL - может многое
- API - гибкость и надежность
    - генерация на активной системе
    - быстрый отклик по корректировке




    

 
 

